{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN From Scratch In Python! \n",
    "This notebook is used for training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import mnist\n",
    "from conv import ConvolutionLayer\n",
    "from maxpool import MaxPoolingLayer\n",
    "from activations import Softmax\n",
    "from training import CNN_train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    ConvolutionLayer(1, 3),\n",
    "    MaxPoolingLayer(2),\n",
    "    Softmax(13*13*1, 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ->\n",
      "Step 1. For the last 1000 steps: average loss 0.0, accuracy 0\n",
      "Step 1001. For the last 1000 steps: average loss 23.14676135835274, accuracy 102\n",
      "Step 2001. For the last 1000 steps: average loss 23.16774706469732, accuracy 101\n",
      "Step 3001. For the last 1000 steps: average loss 23.15284853788595, accuracy 101\n",
      "Step 4001. For the last 1000 steps: average loss 23.171302633865068, accuracy 85\n",
      "Step 5001. For the last 1000 steps: average loss 23.145814478678762, accuracy 104\n",
      "Step 6001. For the last 1000 steps: average loss 23.126318362173237, accuracy 95\n",
      "Step 7001. For the last 1000 steps: average loss 23.168495925745656, accuracy 85\n",
      "Step 8001. For the last 1000 steps: average loss 23.102831775979663, accuracy 101\n",
      "Step 9001. For the last 1000 steps: average loss 22.98813222522287, accuracy 121\n",
      "Epoch 2 ->\n",
      "Step 1. For the last 1000 steps: average loss 0.0, accuracy 0\n",
      "Step 1001. For the last 1000 steps: average loss 22.810937464628232, accuracy 162\n",
      "Step 2001. For the last 1000 steps: average loss 22.52594671617725, accuracy 191\n",
      "Step 3001. For the last 1000 steps: average loss 21.887642120923406, accuracy 359\n",
      "Step 4001. For the last 1000 steps: average loss 21.013176713503476, accuracy 476\n",
      "Step 5001. For the last 1000 steps: average loss 19.319591376725064, accuracy 597\n",
      "Step 6001. For the last 1000 steps: average loss 17.139092723296915, accuracy 666\n",
      "Step 7001. For the last 1000 steps: average loss 14.479019033894488, accuracy 751\n",
      "Step 8001. For the last 1000 steps: average loss 13.090184230655536, accuracy 749\n",
      "Step 9001. For the last 1000 steps: average loss 10.796827722994944, accuracy 758\n",
      "Epoch 3 ->\n",
      "Step 1. For the last 1000 steps: average loss 0.0, accuracy 0\n",
      "Step 1001. For the last 1000 steps: average loss 8.20745459153651, accuracy 807\n",
      "Step 2001. For the last 1000 steps: average loss 7.306695577709169, accuracy 821\n",
      "Step 3001. For the last 1000 steps: average loss 6.147917726935029, accuracy 848\n",
      "Step 4001. For the last 1000 steps: average loss 5.956404353651603, accuracy 876\n",
      "Step 5001. For the last 1000 steps: average loss 5.611332264926749, accuracy 865\n",
      "Step 6001. For the last 1000 steps: average loss 5.317496152007516, accuracy 859\n",
      "Step 7001. For the last 1000 steps: average loss 4.6676101893462265, accuracy 878\n",
      "Step 8001. For the last 1000 steps: average loss 5.678800718629004, accuracy 848\n",
      "Step 9001. For the last 1000 steps: average loss 5.5588238539576285, accuracy 850\n",
      "Epoch 4 ->\n",
      "Step 1. For the last 1000 steps: average loss 0.0, accuracy 0\n",
      "Step 1001. For the last 1000 steps: average loss 4.891886990911541, accuracy 868\n",
      "Step 2001. For the last 1000 steps: average loss 4.553813689653392, accuracy 868\n",
      "Step 3001. For the last 1000 steps: average loss 3.9274839928200866, accuracy 886\n",
      "Step 4001. For the last 1000 steps: average loss 3.9318717007375428, accuracy 904\n",
      "Step 5001. For the last 1000 steps: average loss 4.114299326327909, accuracy 887\n",
      "Step 6001. For the last 1000 steps: average loss 4.01597523840519, accuracy 885\n",
      "Step 7001. For the last 1000 steps: average loss 3.540552197910791, accuracy 894\n",
      "Step 8001. For the last 1000 steps: average loss 4.549065464737152, accuracy 879\n",
      "Step 9001. For the last 1000 steps: average loss 4.7536404162548145, accuracy 865\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    print('Epoch {} ->'.format(epoch+1))\n",
    "    # Training the CNN\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for i, (image, label) in enumerate(zip(X_train[0:10000], Y_train[0:10000])):\n",
    "      if i % 1000 == 0: # Every 1000 examples\n",
    "        print(\"Step {}. For the last 1000 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "      loss_1, accuracy_1 = CNN_train(image, label, layers)\n",
    "      loss += loss_1\n",
    "      accuracy += accuracy_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
